\documentclass[xcolor=svgnames]{beamer}
\usetheme{Boadilla}
\usecolortheme[named=SeaGreen]{structure}
\usepackage{graphicx}
\usepackage{breqn}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{verbatim}
\usepackage{tikz}
\usepackage{lmodern}
\usetikzlibrary{shadows,arrows,positioning}
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks,linkcolor=links,urlcolor=links}
\usepackage{pgfpages}

\newcommand{\Bigtxt}[1]{\textbf{\textit{#1}}}

\begin{document}

\title[Exploratory Data Analysis]{Exploratory Data Analysis with SWMP}

\author[M. Beck, T. O'Brien]{Marcus W. Beck\inst{1} \and Todd D. O'Brien\inst{2}}

\date{}

\institute[]{\inst{1} ORISE, USEPA NHEERL Gulf Ecology Division\\ Email: \href{mailto:beck.marcus@epa.gov}{beck.marcus@epa.gov} \and \inst{2} NOAA/NMFS COPEPOD Project\\ Email: \href{todd.obrien@noaa.gov}{todd.obrien@noaa.gov}}

% knitr setup
<<setup, include = F, cache = F>>=
add_lib <- 'C:\\Users\\mbeck\\R\\library'
if(file.exists(add_lib)) .libPaths(add_lib)
rm('add_lib')
library(knitr)

# set global chunk options
opts_chunk$set(fig.align='center', fig.show='hold',message=F,dev='pdf',dev.args=list(family='serif'),fig.pos='!ht',warning=F,size= 'scriptsize', cache = T)
options(replace.assign=TRUE,width=80,digits=2)
@

% load SWMPr from local
<<swmpr, eval = T, echo = F, cache = F, message = F>>=
devtools::load_all('M:/docs/SWMPr')
@

%%%%%%
\begin{frame}
\vspace{0.3in}
\centerline{
\begin{tikzpicture}
  \node[drop shadow={shadow xshift=0ex,shadow yshift=0ex},fill=white,draw] at (0,0) {\includegraphics[width=0.9\textwidth]{bg_main.jpg}};
\end{tikzpicture}}
\titlepage
\end{frame}

%%%%%%
\begin{frame}{Objectives and agenda}
\begin{itemize}
\onslide<+->
\item Objectives \\~\\
\begin{itemize}
\item What are some basic time series analysis techniques and when would you use them? \\~\\
\item How are the data set up, what functions are used, and how are the results interpreted? \\~\\
\end{itemize}
\onslide<+->
\item Agenda \\~\\
\begin{itemize}
\item Analysis 1 - missing data and interpolation\\~\\
\item Analysis 2 - smoothing and aggregation \\~\\
\item Analysis 3 - basic trend analysis\\~\\
\end{itemize}
\end{itemize}
\end{frame}

%%%%%%
\begin{frame}{Interactive portion}
You can follow along in this module: \\~\\
\begin{itemize}
\item dataset3 \\~\\
\item script3 \\~\\
\end{itemize}
\Large
\centerline{\emph{Interactive!}}
\end{frame}

%%%%%%
\begin{frame}{What is exploratory data analysis (EDA)?}
A general term that describes preliminary evaluation of a variable or multiple variables in a dataset to assess quantitative properties for further analysis or hypothesis generation\\~\\
EDA can inform you of the \alert{types} of variables (categorical, continuous), \alert{distribution} of variables (central tendency, spread), \alert{correlations} between variables, and presence of \alert{outliers} \\~\\
You may decide to omit variables or specific observations, transform, standardize, etc.\\~\\
Many of the same principles that apply to standard data analysis apply to time series analysis
\end{frame}

%%%%%%
\begin{frame}{What is exploratory data analysis (EDA)?}
R has many functions available for EDA - see the \href{http://cran.r-project.org/doc/contrib/Short-refcard.pdf}{R reference card} and the cookbook for some ideas\\~\\
We will cover a few basic techniques but keep in mind EDA is a general term and much of what we have already covered, and will cover, can be considered exploratory \\~\\
A quick google search of `exploratory data analysis in r' will point you in the right direction for generic approaches you might consider \\~\\
For now, we will focus on some tasks that have specific relevance to SWMP
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 1 - Missing data and interpolation}
Time series will usually include missing data - you will have to decide how to handle missing values \\~\\
Let's import some wq data
<<echo = F, cache = F>>=
path <- 'M:/docs/swmp_workshop_2014/training_modules/data/dataset3/' 
wq_dat <- import_local(path, 'cbmmcwq2012')
@
<<eval = F>>=
# import data, qaqc, and subset
# change this path for the flash drive
path <- 'C:/data/dataset3'
wq_dat <- import_local(path, 'cbmmcwq2012')
@
<<cache = F>>=
# qaqc and subset do_mgl
wq_dat <- qaqc(wq_dat)
wq_dat <- subset(wq_dat, select = 'do_mgl')

# how many missing values?
sum(is.na(wq_dat$do_mgl))
@
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 1 - Missing data and interpolation}
Introducing the `na.approx' function - this method can interpolate missing data
<<fig.height = 3, fig.width = 7, out.width = '0.8\\textwidth'>>=
# subset the do time series for plotting
wq_dat <- subset(wq_dat, subset = c('2012-10-01 0:0', '2012-10-31 0:0'))
plot(do_mgl ~ datetimestamp, wq_dat, type = 'l')
@
Notice the missing values around October 12\textsuperscript{th}
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 1 - Missing data and interpolation}
Here's what the time series looks like after using `na.approx'
<<fig.height = 3, fig.width = 7, out.width = '0.8\\textwidth', echo = F>>=
# subset the do time series for plotting
wq_dat <- na.approx(wq_dat, maxgap = 100)
plot(do_mgl ~ datetimestamp, wq_dat, type = 'l')
@
The missing values have been linearly interpolated - a simple function that predicts missing values based on the starting and ending values in gaps\\~\\
May not be a true representation but better than some other approaches
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 1 - Missing data and interpolation}
The `na.approx' function has only a few arguments\\~\\
\begin{itemize}
\item swmpr\_in: input swmpr data \\~\\
\item params: which parameters to interplate, default is all \\~\\
\item maxgap: what is the maximum gap size to interpolate?
\end{itemize}
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 1 - Missing data and interpolation}
Now you try an analysis! Open a new script and try the following: \\~\\
\begin{itemize}
\item Import the file `cbmmcwq2012.csv' in the dataset3 folder \\~\\
\item Handle QAQC flags and subset by October 1 to 31 \\~\\
\item Plot the data - where are the missing values?\\~\\
\item Use `na.approx.swmpr' to interpolate the missing values - what value to use for maxgap?\\~\\
\item Plot the data again - how does it look?
\end{itemize}
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 1 - Missing data and interpolation}
<<eval = F>>=
# the analysis should start like this

# change path as needed
path <- 'C:/data/dataset3'
dat <- import_local(path, 'cbmmcwq2012')

# qaqc and subset imported data
dat <- qaqc(dat)
dat <- subset(dat, subset = c('2012-10-01 00:00', '2012-10-31 00:00'))

# plot
plot(do_mgl ~ datetimestamp, data = dat, type = 'l')
@
Now use na.approx using the data and an appropriate gap size (try 50) \\~\\
Save the results to a new object and plot again \\~\\
Try different gap values, how does this affect the plot or mean DO?
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 1 - Missing data and interpolation}
<<echo = F>>=
# the analysis should start like this

# change path as needed
path <- 'M:/docs/swmp_workshop_2014/training_modules/data/dataset3'
dat <- import_local(path, 'cbmmcwq2012')

# qaqc and subset imported data
dat <- qaqc(dat)
dat <- subset(dat, subset = c('2012-10-01 00:00', '2012-10-31 00:00'))
@
<<fig.height = 2, cache = F, fig.width = 6, out.width = '0.7\\textwidth', echo = T>>=
new_dat <- na.approx(dat, maxgap = 50) # try different maxgaps

# plot
par(mar = c(4.1, 4.1, 0.5, 0.5))
plot(do_mgl ~ datetimestamp, data = new_dat, type = 'l')
@
<<cache = F>>=
mean(dat$do_mgl, na.rm = T)
mean(new_dat$do_mgl, na.rm = T)
@
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 2 - Smoothing and aggregation}
\alert{Problem}: trend evaluation is difficult if the data are noisy \\~\\
Noise can be caused by many factors (e.g., measurement error, process uncertainty), we are usually more concerned with the true signal in a time series \\~\\
Noise can be addressed by aggregating or smoothing data, both are similar \\~\\
The \alert{`aggregate.swmpr'} function aggregates a time series by set periods of observation and calculates summary data for a variable \\~\\
The \alert{`smoother.swmpr'} function calculates a moving window average of a time series \\~\\
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 2 - Smoothing and aggregation}
The (relevant) arguments for `aggregate.swmpr':\\~\\
\begin{itemize}
\item swmpr\_in: Input data object \\~\\
\item by: How are the data aggregated - `year', `quarters', `months', `weeks', `days', `hours' \\~\\
\item FUN: What function is used to aggregate the data? Defaults to mean.
\end{itemize}
<<eval = F>>=
# see help for all arguments
?aggregate.swmpr
@
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 2 - Smoothing and aggregation}
The (relevant) arguments for `smoother.swmpr':\\~\\
\begin{itemize}
\item swmpr\_in: Input data object \\~\\
\item window: the size of the smoothing window, defaults to five observations at the current time step \\~\\
\item sides: what defines the window, centered on an observation (2) or use only the preceding observations (1)  \\~\\
\end{itemize}
<<eval = F>>=
# see help for all arguments
?smoother.swmpr
@
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 2 - Smoothing and aggregation}
Now you try an analysis! Open a new script and try the following: \\~\\
\begin{itemize}
\item Import the the same data as before - `cbmmcwq2012.csv' in the dataset3 folder \\~\\
\item Handle QAQC flags and subset by October 1 to 31 \\~\\
\item Plot the raw data \\~\\
\item Use `smoother.swmpr', save to new object, plot again. How does it look? Try different window sizes.\\~\\
\item Aggregate the data by weeks and view the raw data (do not plot).  Now try aggregation by months, what's the difference?\\~\\
\end{itemize}
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 2 - Smoothing and aggregation}
<<eval = F>>=
# use the same data as in analysis 1

# smooth 
new_dat <- smoother.swmpr(dat, window = 40)

# plot original, then new
plot(do_mgl ~ datetimestamp, data = dat, type = 'l')
plot(do_mgl ~ datetimestamp, data = new_dat, type = 'l')
@
<<echo = F, cache = F, fig.height = 3.5, fig.width = 6, out.width = '0.7\\textwidth'>>=
# smooth 
new_dat <- smoother.swmpr(dat, window = 40)
# plot
par(mar = c(4.1, 4.1, 0.5, 0.5), mfrow = c(2, 1))
plot(do_mgl ~ datetimestamp, data = dat, type = 'l')
plot(do_mgl ~ datetimestamp, data = new_dat, type = 'l')
@
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 2 - Smoothing and aggregation}
<<cache = F>>=
# try an aggregation by 'weeks'
aggregate(dat, by = 'weeks')

# try an aggregation by 'months'
aggregate(dat, by = 'months')
@
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 3 - Basic trend analysis}
Numerical summaries, filling missing data, and smoothing improve our ability to describe the data \\~\\
More often, we are concerned with \alert{long-term trends} over time -- a missing data point here or there or noisy data on short time periods are not very important \\~\\
We need \alert{plots} to characterize long-term trends over time -- both \alert{raw} and \alert{summarized} data \\~\\
This analysis will show you two ways to evaluate trends by plotting -- we will go through it together
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 3 - Basic trend analysis}
Start by importing all the water quality data for the `Iron Pot Landing' station at the Chesapeake Bay Maryland reserve 
<<echo = F>>=
path <- 'M:/docs/swmp_workshop_2014/training_modules/data/dataset3'
dat <- import_local(path, 'cbmipwq')
dat <-qaqc(dat)
@
<<eval = F>>=
# import all wq data for cbmip
# change path as needed
path <- 'C:/data/dataset3/'
dat <- import_local(path, 'cbmipwq')

# qaqc checks
dat <- qaqc(dat)
@
What are the dissolved oxygen dynamics over the last four years?  Can we characterize trends, both seasonal and annual?
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 3 - Basic trend analysis}
First a simple plot...
<<fig.height = 3, fig.width = 8, out.width = '\\textwidth'>>=
# plot DO for the time series
plot(do_mgl ~ datetimestamp, data = dat, type = 'l')
@
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 3 - Basic trend analysis}
If we are concerned with long-term trends, we want to reduce the noise related to intra-annual variability...  we can use the smoother function
<<fig.height = 3, fig.width = 8, out.width = '\\textwidth'>>=
# smoother using a large window 
do_smooth <- smoother(dat, params = 'do_mgl', window = 5000)
plot(do_mgl ~ datetimestamp, data = dat, type = 'l')
lines(do_smooth$datetimestamp, do_smooth$do_mgl, col = 'red')
@
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 3 - Basic trend analysis}
Try it again but use `na.approx' first to fill gaps
<<fig.height = 3, fig.width = 8, out.width = '\\textwidth'>>=
# use na.approx, then smooth
new_dat <- na.approx(dat, param = 'do_mgl', maxgap = 3000)
do_smooth <- smoother(new_dat, params = 'do_mgl', window = 5000)
plot(do_mgl ~ datetimestamp, data = new_dat, type = 'l')
lines(do_smooth$datetimestamp, do_smooth$do_mgl, col = 'red')
@
This is kind of cheating but now we have a time series that primarily shows inter-annual variation
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 3 - Basic trend analysis}
Finally, we can use the `aggregate.swmpr' function with boxplots for an alternative interpretation \\~\\
The `aggs_out' argument in the function can be used to return the data with the datetimestamp formatted according to the `by' argument
<<>>=
# get reformatted data from aggregate for plotting
agg_dat <- aggregate(dat, by = 'months', params = 'do_mgl', aggs_out = T)
head(agg_dat)

# note same row number in aggregated data
dim(agg_dat)
dim(dat)
@
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 3 - Basic trend analysis}
Plot the aggregated data
<<fig.height = 5, fig.width = 9, out.width = '\\textwidth'>>=
# use boxplots 
boxplot(do_mgl ~ datetimestamp, data = agg_dat, ylab = 'do_mgl')
@
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 3 - Basic trend analysis}
This can be repeated for different time steps...
<<fig.height = 5, fig.width = 9, out.width = '\\textwidth'>>=
# by season
agg_dat <- aggregate(dat, by = 'quarters', params = 'do_mgl', aggs_out = T)
boxplot(do_mgl ~ datetimestamp, data = agg_dat, ylab = 'do_mgl')
@
\end{frame}

%%%%%%
\begin{frame}[containsverbatim]{Analysis 3 - Basic trend analysis}
This can be repeated for different time steps...
<<fig.height = 5, fig.width = 9, out.width = '\\textwidth'>>=
# by year
agg_dat <- aggregate(dat, by = 'years', params = 'do_mgl', aggs_out = T)
boxplot(do_mgl ~ datetimestamp, data = agg_dat, ylab = 'do_mgl')
@
\end{frame}

%%%%%%
\begin{frame}{Analysis 3 - Basic trend analysis}
A final note about trend analysis -- this can be as simple or as complex as you like \\~\\
The key question - has my variable of interest significantly changed and when did it occur? \\~\\
You must define what change means and how you will assess \\~\\
E.g., Has it increased/decreased?  How has the central tendency changed?  Has the variance changed?  What factors could have influenced this change?  \\~\\
As a first step, always plot the raw or summarized data! \\~\\
More detailed approaches are beyond the scope of this workshop - but check out the CRAN task view on \href{http://cran.r-project.org/web/views/TimeSeries.html}{time series} for more you can do in R!
\end{frame}

%%%%%%
\begin{frame}
\vspace{0.3in}
\centerline{
\begin{tikzpicture}
  \node[drop shadow={shadow xshift=0ex,shadow yshift=0ex},fill=white,draw] at (0,0) {\includegraphics[width=0.9\textwidth]{bg_main.jpg}};
\end{tikzpicture}}
\vspace{0.5in}
\Large
\centerline{\Bigtxt{Questions??}}
\end{frame}

\end{document}